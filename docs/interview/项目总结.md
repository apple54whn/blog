我叫xxx，来自西安，毕业于xxx的计科专业，之前在广州知客来网络科技有限公司做Java后端开发。我的工作态度、适应能力值得信赖，希望能加入贵公司做出贡献并提高自己。

# 学优网课

学优网课是一个类似慕课网的在线教育网站，采用前后端分离技术，前端使用Vue+node.js，后端使用Spring Cloud的微服务架构。我主要负责后端接口编写和接口文档，给前端提供JSON数据。其中负责的模块有：

* 系统管理中，**CMS管理服务**接口开发：负责因运营需要而经常改变的页面（FreeMaker+RabbitMQ）

  > 如首页广告、轮播图等经常改变页面的采用CMS管理，只需后台修改数据并生成静态页面即可：
  >
  > * 模板管理：将经常改变的页面采用freemarker静态化，存入mongodb提供的分布式大文件管理系统gridfs中。
  > * 模板数据管理：模板一般不会改变，需要经常改变的就是模板数据。
  > * 页面管理：页面管理就是负责页面的基本信息，所属站点等，关联模板和模板数据，通过调用后端页面预览接口查看页面是否正确，正确后调用后台的页面发布接口，会将HTML页面生成，并存入gridfs中。与此同时需要使用rabbitmq消息队列发送消息到各站点的**CMS client微服务**（routingKey为站点id），下载生成的HTML到各自站点。通过部署在nginx中，并发性能好，减轻数据库压力，且利于SEO，方便推广我们的课程。
  >
  > 系统管理中，**数据字典**接口开发（code、name，在CMS微服务中）
  >
  > * 如支付状态：未支付、已支付等，采用code代替。解决硬编码问题，修改名称时只需修改数据字典

* 教学管理中心，**课程管理**服务接口开发

  > * 课程基本信息管理：名称，适用人群，课程分类（用到数据字典），课程营销信息的管理。
  > * 课程展示的小图标保存通过单独的小文件存储微服务使用fastdfs管理，存储详细信息到mongodb中。其中文件URL保存到课程管理服务MySQL中。
  > * 最重要的是课程计划管理模块：根据一张表的parentid字段实现三级教学目录的管理，包括章节名称，课程类型，学习时长等。**添加媒资和课程关联**
  > * **课程预览和课程发布**通过feign远程调用CMS微服务的预览和发布接口。发布成功修改状态即可。

* **文件存储服务**：为了系统可重用性开发单独微服务，采用FastDFS存储

  > 课程展示的小图标保存通过单独的小文件存储微服务使用fastdfs管理，存储详细信息到mongodb中。其中文件URL保存到课程管理服务MySQL中。

* **媒资管理服务**：管理课程所需的媒资文件

  > 点播采用的是HLS协议，将视频拆分成**若干ts格式的小文件**，通过**m3u8格式的索引文件**来播放
  >
  > * 前端采用WebUploader来完成文件的分块上传
  >
  >   * 检测文件是否存在、文件夹是否存在
  >   * 上传分块是否存在
  >   * 上传分块
  >   * 合并分块文件（对比MD5信息），移除分块文件。
  >
  > * 通过RabbitMQ发送消息到媒资处理服务，使用Process Builder执行FFmpeg将上传的文件转换为m3u8和ts文件，
  >
  >   保存信息到MongoDB

  

# 乐购交易平台

乐购交易平台是一个B2B2C的交易平台，采用Dubbo的SOA架构，方便后期伸缩扩展。Controller层用于服务消费者，Service和Dao层用于服务提供者，前后端交互采用JSON数据。我主要负责的有：

* **运营商管理模块**：负责**品牌、规格、规格模板、商品分类**管理等

  > - 品牌管理（brand）：CRUD，模糊查询（后台系统，没有索引）
  >
  > - 规格/选项管理（specification/option）：尺码/网络/内存等；及其选项（提供order列来排序）；
  >
  >   组合对象传递数据；`SELECT LAST_INSERT_ID() AS id`查询保存的规格的ID，并根据ID保存规格选项；
  >
  >   修改时采取删除规格选项，再插入的方式！（由于不清楚添加还是修改规格选项）
  >
  > - 模板管理（type_template）：用于关联品牌和规格！如手机模板关联多个品牌、多个规格，JSON保存；扩展字段
  >
  >   ```json
  >   [{"id":33,"text":"电视屏幕尺寸"}]
  >   ```
  >
  > - 商品分类管理（item_cat）：关联模板。因为每个SKU都有分类id对应，根据parentId查询

* **商品管理模块**：商品的CRUD和图片的上传（FastDFS）

  > - 商品录入（goods、goods_desc、item），多张表的操作，可以封装数据到组合实体类，item即SKU可能有多个
  >
  > - 录入商品SPU的**基本信息**、商品**分类**，通过所属模板查找到**品牌**和**规格/选项**，通过**规格/选项生成多个SKU商品**。并添加默认数据如添加、更新时间等
  >
  >   在上传SPU图片时，因为整个项目需要存储大量图片，所以采用分**布式文件存储系统FastDFS**来存储，后期也可对其容量进行水平扩展。并且对于高并发、高可用的问题，FastDFS 的**容灾性、负载均衡**也是个优势
  >
  > - 运营商后台审核商品，更新商品状态为上架或其他

* **商品详情页**：减轻数据库访问压力，为了SEO，将数据不会经常变换的页面采用静态化的技术部署在Nginx中，高并发性能强

  > Nginx可以承载5万的并发，而Tomcat只有几百

* **Cookie+Redis 实现购物车模块**

* snowflake 分布式ID + 微信扫码支付

  > 64位 snowflake（每秒能够产生26万个ID）：
  >
  > * 1bit不用，为0；
  > * 41bit：时间戳的毫秒值。可以存储69年
  > * 10bit：机器id，可以部署1024个节点
  > * 12bit：毫秒内计数，可产生4096个
  >
  > 微信扫码支付Native（下载官方SDK，内部封装了HttpClient，直接调用方法）：
  >
  > * 统一下单API，生成支付url，订单id，金额等，传给前端生成二维码
  > * 查询订单状态API，Controller层每隔5秒调用一次微信该接口，5分钟后失效，返回给前端（返回Success）
  > * 关闭、撤销订单接口



# 后期提问

公司目前要做的项目类型

公司目前的技术架构



## 购物车使用了 Cookied 和 Redis 缓存

当用户在**未登录**的情况下，将此购物车存入**cookies** , 在用户登陆的情况下，将购物车数据存入**redis**  。如果用户登陆时，cookies 中存在购物车，需要将cookies的购物车**合并**到 redis 中存储。，**降低了数据库的读写次数，提升服务性能**。

- 存储的是：商家ID、商家名称、购物车列表（存储商品明细），采用组合实体类封装
- 传入数据：SKU ID、SKU数量（可能为负数）

> `access="IS_AUTHENTICATED_ANONYMOUSLY"` 用于设置**资源可以在不登陆时可以访问**，此配置与 `security="none"`的区别在于当用户未登陆时获取登陆人**账号的值为`anonymousUser`** ，而`security="none"`的话，无论是否登陆都不能获取登录人账号的值（在获取时就报空指针异常，因为不走SpringSecurity）

利用Spring Security获取当前登录的用户名，存在如下两种情况：

1. 未登录

   1. 从Cookie中**提取我的购物车**

   2. 向Cookie中**添加商品**

      因为有第三方商家，所以需要判断**该商品所属商家的购物车是否在我的购物车中**

      - 不存在则**创建商品所属的商家购物车**，并**添加到的购物车列表中**

      - 存在则需要**判断**当前**商品**是否存在于商家购物车

        - 不存在则**创建商品**明细并**添加至该商家购物车**中

        - 存在则修改商品数量即可

          数量为0时则删除该商品；购物车列表长度小于等于0时删除该商家购物车

   3. 最终将我的购物车**存入Cookie**

2. 已登录

   1. 从Redis中**提取我的购物车**，根据登陆名称存放的
   2. 查询**Cookie中是否存在**我的购物车（size>0），存在则**合并我的购物车**（遍历，并调用上面1.2中方法）
   3. 向购物车**添加商品**（还是上面1.2中方法）
   4. 最终将我的购物车**存入Redis**





## Dubbo

dubbo 在我们项目中主要用来实现**不同系统之间的服务调用**，由于我们项目是**按照不同的功能分了不同的系统**，按照三层架构又**分了不同的服务**，其中三层架构中的**控制层作为服务的消费方**，**业务层和持久层共同作为服务的发布方**，这样的架构实现了**系统的服务化，提高了开发效率，实现了业务的解耦**。 

我们主要在服务的暴露方通过`<dubbo:service>`标签来暴露服务，在服务的消费方通过`<dubbo:reference>`标签来引用服务，注册中心我们选用的是 zookeeper，对服务的URL 进行了管理和配置。



- Dubbo 是阿里开源的 **RPC（远程过程调用） 的分布式框架**，提供了 SOA 服务治理方案。有5个分为是Provider（服务
  的提供方）、Consumer（服务的消费方）、Container（容器）、Registry（注册中心）、Monitor（监控中心）
- **注册中心**：只负责**发现和注册服务**。不参与数据传输，不转发请求，压力较小
  - 注册中心宕机问题
    - 注册中心会集群部署，其中一台宕机，自动切换到另一台。
    - 全部宕机后还可以通过本地缓存通信
- **监控中心**：负责统计各**服务调用次数、调用时间**等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示 



在使用Duubo 的过程中你们遇到过什么问题？ 

- 序列化和反序列化异常

  调用服务，出现消息发送失败的时候，通常是接口方法的**传入传出参数是新增加的扩展类**，**没有实现序列化接口**

- 怎么禁止一个服务？

  **通过监控中心**的可视化界面，我们可以对具体的服务设置禁止，也可以设置对应的权重



## Zookeeper

### 简介

我们项目中主要用 zookeeper 作为 Dubbo 的**注册中心**，集中**管理所有服务的 URL**；同时集中的管理集群的配置。 

为什么要用zookeeper 作为dubbo 的注册中心？

zookeeper 的**数据全部存储在内存中**，性能高；其次， zookeeper 也**支持集群**，实现了高可用；同时基于 zookeeper 的特性，也支持**事件监听**（服务的暴露方发生变化，可以进行推送），所以zookeeper 适合作为 dubbo 的注册中心区使用。



### 集群简介

为什么搭建Zookeeper集群？

- 大部分分布式应用需要一个主控、协调器或者控制器来管理物理分布的子进程。目前，大多数都要开发私有的协调程序，缺乏一个通用机制，协调程序的反复编写浪费，且难以形成通用、伸缩性好的协调器，zookeeper提供通用的分布式锁服务，用以协调分布式应用。所以说zookeeper是分布式应用的协作服务。
- zookeeper**作为注册中心，服务器和客户端都要访问，如果有大量的并发肯定会有等待。所以可通过zookeeper集群解决。**

------

**Leader选举**

Zookeeper的启动过程中leader选举是非常重要而且最复杂的一个环节。那么什么是leader选举呢？zookeeper为什么需要leader选举呢？zookeeper的leader选举的过程又是什么样子的？

首先我们来看看什么是leader选举。其实这个很好理解，leader选举就像总统选举一样，每人一票，获得多数票的人就当选为总统了。在zookeeper集群中也是一样，每个节点都会投票，如果某个节点获得**超过半数以上的节点的投票**，则该节点就是leader节点了。

> 以一个简单的例子来说明整个选举的过程：
> 	假设有**五台服务器组成的zookeeper集群,**它们的id从1-5,同时它们都是最新启动的,也就是没有历史数据,在存放数据量这一点上,都是一样的.假设这些服务器依序启动,来看看会发生什么 。
> 	1) 服务器1启动,此时只有它一台服务器启动了,它发出去的报没有任何响应,所以它的选举状态一直是LOOKING状态  
> 	2) 服务器2启动,它与最开始启动的服务器1进行通信,互相交换自己的选举结果,由于两者都没有历史数据,所以id值较大的服务器2胜出,但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是3),所以服务器1,2还是继续保持LOOKING状态.  
> 	3) 服务器**3**启动,根据前面的理论分析,服务器3成为服务器1,2,3中的老大,而与上面不同的是,此时有三台服务器选举了它,所以它成为了这次选举的**leader**.  
> 	4) 服务器4启动,根据前面的分析,理论上服务器4应该是服务器1,2,3,4中最大的,但是由于前面已经有半数以上的服务器选举了服务器3,所以它只能接收当小弟的命了.  
> 	5) 服务器5启动,同4一样,当小弟





## RabbitMQ

### 为什么使用消息队列？

我们CMS服务有个发布接口，发布成功后需要将生成的静态HTML文件下载到其对应的服务器。可以使用MQ来实现解耦和异步



### 消息队列有什么优缺点？

* 优点：解耦、异步、削峰
* 缺点：**系统复杂度提高**、**可用性**降低，会有**一致性**问题



### ActiveMQ、RabbitMQ、RocketMQ、Kafka 有什么优缺点？

* ActiveMQ：社区不活跃
* RabbitMQ：时效性为微秒级，基于erlang开发，并发性好
* RocketMQ：阿里开源，捐赠给Apache，功能完善，分布式。可以消息0丢失
* Kafka：用于大数据领域



### 如何保证消息队列的高可用？

采用镜像集群模式。创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。



### 如何保证消息不被重复消费？如何保证消息消费的幂等性？

保证**被消费的数据在数据库中只有一条记录！**

* 每次写数据库时根据主键之类**查询**，有就不保存了
* Redis每次都是set，天然幂等
* 若是用类似**分布式id等全局id，消费前查询一下**，保证别重复消费即可。或用**唯一约束**来制约



### 如何保证消息的可靠性传输？如何处理消息丢失的问题？

> 不用RabbitMQ的事务机制，同步会吞吐量下降，损耗性能

* MQ开启**持久化**，持久化交换机/队列/消息

* 生产者开启**confirm模式**（分配id），发送到MQ并持久化则返回成功，否则返回失败，此时可以重试。定时重试

* 消费者关闭**自动ACK机制**，在处理完业务后才ACK，否则MQ会把消息交给其他消费者处理

  

### 如何保证消息的顺序性？

拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点。



### 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？

> 消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 hang 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。

* 扩容
* 过期消失：将过期消息查询出来，并传入MQ
* 



### 发布订阅模式

1、每个消费者监听自己的队列。

2、生产者将消息发给broker，由**交换机将消息转发到绑定此交换机的每个队列**，每个绑定交换机的队列都将接收到消息

==案例：**用户通知**，当用户充值成功或转账完成系统通知用户，通知方式有**短信、邮件**多种方法 。==



### 路由模式

1、每个消费者监听自己的队列，并且设置routingkey。

2、生产者将消息发给交换机，由**交换机根据routingkey来转发消息到指定的队列**。



### 带通配符的路由模式

==**根据用户的通知设置去通知用户**，设置接收Email的用户只接收Email，设置接收sms的用户只接收sms，设置两种通知类型都接收的则两种通知都有效。==

```java
//绑定email通知队列
channel.queueBind(QUEUE_INFORM_EMAIL,EXCHANGE_TOPICS_INFORM,"inform.#.email.#");
//绑定sms通知队列
channel.queueBind(QUEUE_INFORM_SMS,EXCHANGE_TOPICS_INFORM,"inform.#.sms.#");
```



### 为什么使用消息队列？

- 解耦：其他系统都要这个数据，只需要订阅这个队列即可，不和本系统直接打交道
- 异步：对于写操作来说，不需要获取结果，可以采用异步方式
- 削峰：存放在MQ中，慢慢消费，无论有多少请求进入MQ



### 如何保证消息队列的高可用？

**镜像集群模式**：创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。



### RabbitMQ如何保证可靠性传输？

持久化：持久化交换机、队列、消息

ACK确认机制：

* 消息发送确认：
  * **ConfirmCallback消息正确到达 Exchange 中时回调**（有个消息唯一标示来确定哪条消息）
  * **ReturnCallback消息没有正确到达QUEUE时**触发回调，如果正确到达队列不执行
* 手动消息接收确认（根据是否包含error来确认或拒绝）

消息发送、消息接收时**记录日志，定时轮询**，没发送的继续发送。



## SpringTask-Cron表达式

Seconds Minutes Hours DayofMonth Month DayofWeek Year（只能省略最后一位，且俩最长的不能同时出现，其中一个必为?）

```java
@Scheduled(cron = "0 * * * * ?")
```

0 0 10,14,16 * * ? 每天上午10点，下午2点，4点 
0 0/30 9-17 * * ? 朝九晚五工作时间内每半小时 
0 0 12 ? * WED 表示每个星期三中午12点 
"0 0 12 * * ?" 每天中午12点触发 
"0 15 10 ? * *" 每天上午10:15触发 
"0 15 10 * * ?" 每天上午10:15触发 
"0 15 10 * * ? *" 每天上午10:15触发 
"0 15 10 * * ? 2005" 2005年的每天上午10:15触发 
"0 * 14 * * ?" 在每天下午2点到下午2:59期间的每1分钟触发 
"0 0/5 14 * * ?" 在每天下午2点到下午2:55期间的每5分钟触发 
"0 0/5 14,18 * * ?" 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 
"0 0-5 14 * * ?" 在每天下午2点到下午2:05期间的每1分钟触发 
"0 10,44 14 ? 3 WED" 每年三月的星期三的下午2:10和2:44触发 
"0 15 10 ? * MON-FRI" 周一至周五的上午10:15触发 
"0 15 10 15 * ?" 每月15日上午10:15触发 
"0 15 10 L * ?" 每月最后一日的上午10:15触发 
"0 15 10 ? * 6L" 每月的最后一个星期五上午10:15触发 
"0 15 10 ? * 6L 2002-2005" 2002年至2005年的每月的最后一个星期五上午10:15触发 
"0 15 10 ? * 6#3" 每月的第三个星期五上午10:15触发



## Spring Cloud

### springcloud如何实现服务注册发现

服务在发布时 指定对应的服务名（服务名包括了IP地址和端口） 将服务注册到注册中心（eureka或者zookeeper），@EnableDisscoveryClient会被带@EnableEurekaServer的Eureka服务发现并注册。

